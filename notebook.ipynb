{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import os\n",
    "from IPython import display\n",
    "from mediocreatbest import auto\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.40203012e-02  6.48696199e-02 -1.82572305e-01 -4.31613885e-02\n",
      " -8.05139448e-03 -1.37020706e-03  1.51456585e-02  1.93786211e-02\n",
      "  3.73148546e-02 -7.11331982e-03  7.52123538e-03 -3.74110648e-03\n",
      "  6.80238083e-02 -1.22870980e-02  8.82272236e-03 -6.46008626e-02\n",
      " -1.49168167e-03 -6.24026731e-02 -4.85682786e-02  2.28285026e-02\n",
      " -3.82725820e-02 -1.41238477e-02  2.31133448e-03  2.66679246e-02\n",
      "  5.51071279e-02  1.47421453e-02  2.84639075e-02  4.03909646e-02\n",
      " -5.08257598e-02  6.79587387e-03  2.74963211e-02 -8.91831424e-03\n",
      "  1.34069752e-03 -7.32021555e-02 -5.66173606e-02 -4.07984033e-02\n",
      " -8.64307955e-03  5.91476168e-03 -1.52563434e-02  6.08852739e-03\n",
      "  3.62993591e-02 -2.32765414e-02  6.45546243e-02 -5.85643947e-02\n",
      " -3.44178081e-03  2.94390041e-02  4.19890806e-02  3.48086655e-02\n",
      "  9.38842259e-03 -2.66434252e-02  6.19300529e-02 -1.65033434e-02\n",
      " -2.09691422e-03 -1.97864566e-02  5.01455180e-02  7.67891258e-02\n",
      "  5.21950237e-02  3.87457162e-02  1.57717895e-02  3.81537108e-03\n",
      "  5.74190505e-02  7.67603330e-03 -1.29598724e-02  5.28244153e-02\n",
      "  1.58939809e-02 -6.48105219e-02 -2.46190876e-02  5.99451773e-02\n",
      " -1.70476921e-02 -3.55513138e-03  3.06992456e-02 -1.74581297e-02\n",
      "  5.27190156e-02  5.09595387e-02 -1.19015863e-02  9.47821233e-03\n",
      " -7.67166167e-03  2.67063677e-02  1.85406972e-02  3.80336568e-02\n",
      " -8.54929909e-03  1.49832238e-02  1.14252321e-01  2.66189408e-02\n",
      "  9.43442341e-03 -2.78847590e-02  1.90624909e-04 -1.68589465e-02\n",
      " -3.17172073e-02  3.11389510e-02  2.24392675e-02  2.68381052e-02\n",
      " -2.82315211e-03  4.81684096e-02 -7.14786872e-02  8.84676469e-04\n",
      " -2.96923276e-02  2.98697911e-02 -6.31731516e-03 -2.29358748e-02\n",
      "  9.60585475e-03  1.78594682e-02  2.57470738e-02 -1.60396245e-04\n",
      "  9.97003540e-03  6.46775290e-02  2.43004281e-02  1.53067615e-02\n",
      "  3.18775587e-02 -9.82444081e-03 -6.26460090e-02  5.68632670e-02\n",
      " -5.10528218e-03 -2.61596441e-02  8.95581096e-02  2.23309658e-02\n",
      "  8.18717778e-02 -5.04299998e-02  2.78452900e-03  3.58436033e-02\n",
      " -2.91284882e-02 -2.39746179e-02 -1.49335973e-02  6.21743128e-02\n",
      "  4.07378562e-03 -2.12761723e-02 -2.66277120e-02  6.59722537e-02\n",
      "  4.85077985e-02  2.62620626e-03 -5.40426001e-02 -6.32896274e-02\n",
      " -2.47490034e-02 -6.47054100e-03  3.17569077e-02 -6.36127964e-03\n",
      " -4.71638963e-02 -1.21179046e-02 -7.80244404e-03  2.66559012e-02\n",
      "  6.04281612e-02 -1.26387300e-02 -5.69195040e-02  8.99088942e-03\n",
      "  7.06567056e-03 -3.08252126e-02  8.42637867e-02 -1.72460936e-02\n",
      " -9.63875465e-03 -3.94538119e-02  6.38847146e-03  1.39849940e-02\n",
      " -2.19222251e-02  8.69917742e-04  1.89633202e-02  1.10347858e-02\n",
      " -2.42767744e-02 -2.20436286e-02  1.64905488e-02  1.79102400e-03\n",
      "  4.30754526e-03 -2.09730901e-02 -4.91587408e-02  8.12220201e-02\n",
      "  6.26028283e-03 -2.66648550e-02  3.82791944e-02 -8.15952383e-03\n",
      " -4.48280908e-02  6.49440736e-02 -1.11056529e-02 -6.64290041e-02\n",
      "  2.61782315e-02 -5.65503091e-02  1.15142008e-02 -1.57961864e-02\n",
      "  3.00703943e-02 -2.76473854e-02  4.45862412e-02 -4.88319285e-02\n",
      "  1.17552429e-02 -2.49991417e-02  2.46834736e-02 -8.25779419e-03\n",
      " -1.08402167e-02 -3.15200128e-02 -1.10339150e-02  3.22792605e-02\n",
      " -8.77040774e-02  1.79699138e-02 -1.02567570e-02  2.52542105e-02\n",
      " -2.23232759e-03 -5.99460378e-02 -5.68469204e-02 -4.26523536e-02\n",
      "  3.65285203e-02  3.37851122e-02  3.61894281e-03 -5.36047667e-02\n",
      "  2.67694760e-02  1.60775043e-03 -1.26575446e-03  2.80636046e-02\n",
      " -3.09396069e-02  8.84962827e-02  5.58056403e-03  3.61414701e-02\n",
      " -3.66821103e-02  8.66565108e-03  7.62868226e-02 -5.56160025e-02\n",
      " -1.82420742e-02  5.93268778e-03 -3.04096397e-02 -8.43258649e-02\n",
      " -6.07251795e-03 -1.90693270e-02  8.45590793e-03  7.23043382e-02\n",
      "  7.06348494e-02 -5.44465706e-03  3.44322994e-02 -4.38835546e-02\n",
      "  5.91619909e-02  1.61964614e-02 -2.13936379e-04 -2.32542139e-02\n",
      " -5.09072207e-02 -1.19205182e-02 -1.90975238e-02 -5.71432188e-02\n",
      "  5.85997589e-02  4.32482250e-02  1.20419301e-02  3.19983363e-02\n",
      "  7.09776999e-03  3.65161374e-02 -1.88166089e-02  2.72642635e-02\n",
      "  3.56237404e-02  3.13773118e-02  5.39352521e-02 -4.72410023e-02\n",
      " -2.66284514e-02  1.54266125e-02 -2.35240366e-02  3.16803344e-03\n",
      "  4.23702225e-02  7.57826772e-03 -3.24376971e-02 -5.84415458e-02\n",
      " -1.71618210e-03  5.77741079e-02  1.03326598e-02 -1.89463757e-02\n",
      " -1.29236504e-02  2.23750211e-02  2.90330835e-02  9.16520134e-03\n",
      " -1.87234171e-02 -1.38745112e-02  6.90202564e-02 -4.57365811e-02\n",
      " -2.05395687e-02  4.07434516e-02  5.89329423e-03  8.21076147e-03\n",
      "  1.19290026e-02  1.75291579e-02  9.65247769e-03 -2.70568803e-02\n",
      "  5.59185445e-03  2.14839820e-02  2.41476241e-02 -1.26697812e-02\n",
      "  2.08361614e-02 -4.17173058e-02 -4.96120118e-02  8.79531540e-03\n",
      "  2.88155042e-02  6.79448131e-04 -1.25045972e-02 -1.41332028e-02\n",
      "  7.92455114e-03  3.31805274e-02  4.77428809e-02  4.05504145e-02\n",
      "  2.08149645e-02  2.18103267e-02 -5.17909275e-03 -2.35539023e-02\n",
      " -2.15448346e-02  7.64178410e-02 -1.32596735e-02  2.52022631e-02\n",
      "  7.61599094e-02  3.33311013e-03 -9.58819594e-03 -5.77152073e-02\n",
      "  6.17649266e-03  1.65141921e-03  3.72900367e-02  3.59074324e-02\n",
      " -6.85067941e-03 -3.56102847e-02  3.96376513e-02 -1.06403762e-02\n",
      "  8.52661058e-02 -1.41481413e-02 -5.77080771e-02 -3.17524709e-02\n",
      " -5.09407111e-02  6.62652925e-02 -1.76038500e-02  4.95566018e-02\n",
      "  3.12817805e-02  3.15119103e-02  6.33229315e-02  1.68810710e-02\n",
      " -4.30558249e-02 -4.44889776e-02 -4.20431346e-02 -3.78327630e-02\n",
      " -1.55355362e-02  2.56363768e-02 -1.26354359e-02  3.29888947e-02\n",
      "  3.21212225e-02 -1.69354789e-02 -1.09336851e-02  4.68750745e-02\n",
      " -1.25815570e-02 -9.06742364e-02 -1.27015030e-02 -3.79063301e-02\n",
      "  5.33545464e-02 -2.45540254e-02 -4.30423282e-02  1.67114511e-02\n",
      "  4.73871008e-02 -4.37902333e-03 -5.79357240e-03 -7.44089633e-02\n",
      "  2.62829736e-02 -2.92582493e-02 -5.71877211e-02  4.18116292e-03\n",
      "  1.11698778e-02 -3.73949949e-03 -4.00681868e-02 -1.75898187e-02\n",
      " -9.01829824e-03  3.49794477e-02  9.38700885e-03  3.87562928e-03\n",
      "  3.91762815e-02 -7.96929561e-03  1.66700464e-02  1.27523800e-03\n",
      "  3.68707590e-02 -5.20898635e-03 -4.97863479e-02 -1.02406731e-02\n",
      "  5.44094555e-02  1.99908298e-02  6.95641898e-03  5.07126935e-03\n",
      "  1.89267993e-02 -2.98987725e-03 -4.50973473e-02 -2.31572073e-02\n",
      " -3.02723404e-02  5.15116192e-02  2.72819269e-02 -1.88383572e-02\n",
      " -9.11455154e-02 -3.44723836e-02 -4.74168472e-02  9.71064903e-03\n",
      "  5.19578047e-02 -1.87931526e-02  2.79924814e-02 -2.42035072e-02\n",
      "  2.23661084e-02 -8.17370508e-03 -3.18216681e-02 -1.11073060e-02\n",
      "  1.25694845e-03 -1.13893365e-02  3.23179327e-02 -4.93174344e-02\n",
      "  6.34714402e-03  3.54328491e-02  2.70844903e-02 -2.74488144e-02\n",
      "  2.54739225e-02 -2.69524660e-03  1.20110009e-02  3.44891213e-02\n",
      " -3.46584469e-02 -5.93169704e-02  3.21070179e-02  1.35918045e-02\n",
      " -5.32894433e-02  2.63427012e-02 -1.74724928e-03 -5.90720214e-02\n",
      " -5.45182591e-03  1.33334706e-02  1.74292121e-02  3.07605658e-02\n",
      " -1.83158461e-02 -5.66614093e-04  1.38598690e-02  1.91036984e-02\n",
      " -1.29748555e-02  1.99906789e-02 -8.92306678e-03  1.92522688e-03\n",
      "  7.35897422e-02  7.03760013e-02 -3.47313993e-02  2.38143653e-02\n",
      "  4.79503646e-02  1.42684476e-02 -1.39450943e-02  1.23227304e-02\n",
      "  6.26958301e-03 -8.75652730e-02  8.53934698e-03  8.83111730e-02\n",
      " -1.14386119e-02  1.04446141e-02  5.36723807e-03 -3.35331634e-03\n",
      " -2.78378725e-02  4.02143747e-02  5.95243229e-03  4.76633869e-02\n",
      "  2.23486889e-02 -3.39964218e-02  1.54938118e-03  2.59401631e-02\n",
      "  1.36174615e-02  6.85212687e-02  6.88676983e-02 -7.52822012e-02\n",
      " -4.43084016e-02  5.58684990e-02 -4.83479127e-02  3.23242582e-02\n",
      "  9.40922089e-03 -2.62924214e-03  5.25594130e-02 -6.30874038e-02\n",
      "  1.90321673e-02 -2.11882126e-02  6.90647587e-03  1.49935950e-03\n",
      "  4.67616357e-02 -1.11403298e-02 -2.44263536e-03  3.66997533e-02\n",
      "  2.63288524e-02 -2.42765602e-02 -4.43264805e-02 -3.17949504e-02\n",
      " -1.60150342e-02  3.92477810e-02 -8.25451761e-02 -1.37597248e-02\n",
      "  6.22528605e-02 -5.20840138e-02 -1.82355214e-02  1.16011687e-02\n",
      " -4.10987958e-02 -1.71270017e-02  1.80097893e-02  2.08309498e-02\n",
      "  5.20566478e-02 -1.88852921e-02 -3.68449241e-02 -3.79146375e-02\n",
      "  3.40755028e-03  1.52773615e-02  2.76492592e-02 -1.72672402e-02\n",
      "  6.05184399e-02 -8.60158761e-04  4.51860391e-02  2.67687365e-02\n",
      " -1.47207109e-02  2.55163182e-02 -9.96017084e-03 -4.83068489e-02\n",
      " -1.65254697e-02  2.41944492e-02  2.13745777e-02 -1.07110953e-02\n",
      "  5.07516265e-02  7.97916390e-03 -6.78964891e-03  2.79184710e-02\n",
      "  1.50326733e-02  1.33589786e-02 -2.57336125e-02 -1.03370650e-02\n",
      " -5.54765239e-02  4.45395671e-02 -2.59211138e-02 -9.73134674e-03\n",
      "  2.67945994e-02  1.55092971e-02 -6.71688654e-03 -2.43988773e-03\n",
      "  5.85535876e-02 -1.63437128e-02 -2.03731805e-02  2.81384904e-02\n",
      "  8.23296513e-03 -2.85895206e-02 -9.57027078e-03 -2.78927153e-03\n",
      " -3.17131691e-02 -6.58261823e-03  1.68758184e-02 -5.17957881e-02\n",
      " -8.44005588e-03 -3.67141142e-02 -3.98430154e-02 -2.90387403e-02\n",
      " -4.51762527e-02  4.97457525e-03 -1.54544394e-02 -1.19122509e-02\n",
      " -4.54092063e-02 -2.28367746e-02 -2.58965860e-03  1.10800974e-02\n",
      " -1.81329232e-02 -5.24054607e-03 -3.92938778e-02  5.68816671e-03\n",
      "  2.85515357e-02 -6.43117353e-03 -1.17937131e-02 -3.84736136e-02\n",
      "  3.33513599e-03 -3.12072672e-02  3.93062904e-02 -3.88428196e-02\n",
      " -3.82472835e-02 -4.17571366e-02  1.10760042e-02 -6.82063773e-02\n",
      "  2.11572945e-02  1.51757691e-02 -8.58784243e-02 -7.45421415e-03\n",
      "  1.36598079e-02  1.24646618e-03  8.97602290e-02 -1.81539487e-02\n",
      "  2.32384144e-03  1.46850785e-02 -2.41832808e-02 -3.54988500e-03\n",
      "  1.03394175e-02  5.81099931e-03 -3.72820199e-02 -6.69675767e-02\n",
      " -4.61333198e-03 -2.40785368e-02  3.36872856e-03  2.69134194e-02\n",
      "  7.57477246e-03  3.03110313e-02 -2.78473962e-02  1.29623443e-03\n",
      " -6.48683775e-03 -4.78174500e-02  1.93727426e-02  1.10791977e-02\n",
      " -2.24164338e-03 -1.25742676e-02  3.10528371e-03 -7.81626347e-03\n",
      "  6.12911545e-02  1.52397444e-02 -4.13494147e-02  4.74546067e-02\n",
      " -1.83651801e-02 -5.21829992e-04  2.03337353e-02 -3.24647836e-02\n",
      "  3.26381065e-04 -8.26843828e-03  7.81129766e-03 -5.07726073e-02\n",
      "  2.34212144e-03  4.36720066e-02  9.03016701e-03 -4.42134552e-02\n",
      "  1.78030301e-02  4.43577990e-02  3.26947160e-02  3.60088353e-03\n",
      " -4.49350439e-02  1.03886332e-02  3.18696834e-02 -2.30179098e-03\n",
      "  1.38980374e-02 -5.28174080e-02  3.65464576e-02 -2.74350476e-02\n",
      "  2.81746425e-02 -5.22003137e-03  9.06070229e-03 -5.33845685e-02\n",
      " -4.82908711e-02 -5.44391684e-02  4.66140397e-02  1.16946520e-02\n",
      "  6.10809661e-02  3.90651124e-03 -8.71780142e-02 -4.31271493e-02\n",
      "  6.13330528e-02  1.87583379e-02 -2.12826417e-03  2.60298718e-02\n",
      " -8.91859904e-02 -6.95270747e-02 -3.86920981e-02  4.20441367e-02\n",
      " -2.48339791e-02 -2.25894134e-02  1.52722495e-02  4.94769774e-02\n",
      "  4.94205058e-02  1.70087032e-02 -2.38680467e-02  3.25460266e-03\n",
      "  4.02265973e-02 -7.67040774e-02  5.18225133e-02  4.11587730e-02\n",
      "  2.86408849e-02  1.68079715e-02  6.46282658e-02  5.74356951e-02\n",
      "  2.91018169e-02 -1.09899277e-03  1.14269089e-02 -4.48458493e-02\n",
      "  2.30248142e-02 -4.28602174e-02 -8.21884200e-02 -4.63823266e-02\n",
      "  1.51442038e-02  1.18100364e-02 -4.87551279e-02 -3.87740284e-02\n",
      "  3.39706093e-02 -2.46681701e-02  4.89854068e-03 -4.60626408e-02\n",
      " -7.42572546e-02 -2.27054488e-02  2.12780107e-02 -4.42862585e-02\n",
      "  1.23418951e-02  8.65207799e-03  1.28404535e-02  1.86355617e-02\n",
      "  6.81543872e-02 -1.98300704e-02  4.78024594e-03 -2.76698340e-02\n",
      "  2.94972840e-03 -1.01405429e-02  4.72931229e-02 -1.31512713e-03\n",
      "  1.31650828e-02 -3.36976945e-02 -6.80788839e-03 -2.00085267e-02\n",
      "  1.40984738e-02 -2.65938397e-02 -2.81280316e-02 -5.57409376e-02\n",
      "  1.17635829e-02 -3.43871675e-02  4.85813208e-02 -4.77245301e-02\n",
      " -1.41732479e-02  1.43429413e-02  1.40304826e-02  2.24681664e-02\n",
      " -3.02411267e-03  3.93528379e-02 -1.97908636e-02  2.23864987e-02\n",
      " -4.07038294e-02  2.57073026e-02  1.08051440e-02 -7.51272636e-03\n",
      "  8.53402168e-03  8.48744512e-02  1.05717629e-02  1.33294966e-02\n",
      " -3.09816357e-02  1.74585208e-02  2.43743733e-02  1.42683722e-02\n",
      " -9.53629147e-03 -2.84863245e-02  1.61221325e-02  1.61688626e-02\n",
      "  4.75984402e-02 -1.72718316e-02 -8.60793591e-02 -1.63513441e-02\n",
      " -8.05269275e-03 -2.42373557e-03  3.93547080e-02 -4.18026336e-02\n",
      "  1.65928844e-02  2.09543910e-02  2.33279262e-02 -1.73821226e-02\n",
      " -3.00002489e-02  7.68231601e-02 -3.12464796e-02 -2.97100469e-02\n",
      " -4.65060398e-02 -2.55894866e-02 -9.55551490e-02 -4.92984876e-02\n",
      " -3.11460849e-02  5.50646894e-02  2.98596686e-03 -3.46600786e-02\n",
      " -1.50232119e-02 -1.99878775e-02 -4.74651717e-02  7.23333098e-03\n",
      "  6.53261319e-02  4.90754982e-03 -5.14250307e-04 -4.77057770e-02\n",
      " -3.52920443e-02 -2.12583654e-02  5.32290451e-02 -4.10934389e-02\n",
      " -2.98562944e-02  2.86985412e-02  5.79164289e-02 -4.75604134e-03\n",
      "  2.27069948e-02 -6.47495501e-03  1.18315909e-02 -2.31820941e-02\n",
      "  1.18656773e-02 -3.26307267e-02 -7.99597800e-02 -1.79460887e-02]\n"
     ]
    }
   ],
   "source": [
    "os.environ['LLAMA_API_KEY'] = '73AYWHQDREVb9sQpvDjbu2oxSQoERZjW'\n",
    "\n",
    "class _LLM:\n",
    "    \"\"\"\n",
    "    A class for interacting with a language model API to generate completions and embeddings.\n",
    "\n",
    "    The LLM class provides methods to send prompts to a language model API and retrieve the\n",
    "    generated completions or embeddings. It handles the details of the API request and response,\n",
    "    and provides options for caching results to avoid redundant API calls.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : str or None, default=None\n",
    "        The name of the language model to use for generating completions and embeddings.\n",
    "        If None, the model must be specified in each call to `complete` or `embed`.\n",
    "\n",
    "    api_url : str\n",
    "        The URL of the API endpoint to use for generating completions and embeddings.\n",
    "\n",
    "    api_key : str or None, default=...\n",
    "        The API key to use for authentication when making requests to the API. If not specified,\n",
    "        the `api_key_name` parameter must be specified to retrieve the key from the Colab\n",
    "        user data.\n",
    "\n",
    "    api_key_name : str or None, default=None\n",
    "        The name of the Colab user data key that stores the API key. If None, the `api_key`\n",
    "        parameter must be specified directly.\n",
    "\n",
    "    session : requests.Session or None, default=None\n",
    "        The `requests.Session` object to use for making API requests. If None, a new session\n",
    "        will be created.\n",
    "\n",
    "    prompt_kwargs : dict or None, default=None\n",
    "        A dictionary of default keyword arguments to use for the `complete` method. These\n",
    "        arguments will be merged with any arguments specified in each call to `complete`.\n",
    "\n",
    "    cache : dict or None, default=None\n",
    "        A dictionary to use as a cache for storing API responses. If None, a new empty\n",
    "        dictionary will be created.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    complete(**prompt) -> dict\n",
    "        Generate a completion for the given prompt using the language model API.\n",
    "\n",
    "    embed(input) -> numpy.ndarray\n",
    "        Generate embeddings for the given input text or texts using the language model API.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        model: str | None = None,\n",
    "        api_url: str,\n",
    "        api_key: str | None | Ellipsis = ...,\n",
    "        api_key_name: str | None = None,\n",
    "        session: auto.requests.Session | auto.typing.Literal[...] = ...,\n",
    "        prompt_kwargs: dict[str, auto.typing.Any] | None = None,\n",
    "        cache: dict[str, auto.typing.Any] | auto.typing.Literal[...] | None = ...,\n",
    "        lock: auto.threading.Lock | auto.typing.Literal[...] | None = ...,\n",
    "    ):\n",
    "        if api_key is Ellipsis:\n",
    "            assert api_key_name is not None, \\\n",
    "                \"Either 'api_key' or 'api_key_name' must be specified.\"\n",
    "            api_key = auto.mediocreatbest.getpass(api_key_name)\n",
    "\n",
    "        if session is ...:\n",
    "            session = auto.requests.Session()\n",
    "        if prompt_kwargs is None:\n",
    "            prompt_kwargs = {}\n",
    "        if cache is ...:\n",
    "            cache = {}\n",
    "        if lock is ...:\n",
    "            lock = auto.threading.Lock()\n",
    "\n",
    "        self.default_model = model\n",
    "        self.default_api_url = api_url\n",
    "        self.default_api_key = api_key\n",
    "        self.default_session = session\n",
    "        self.default_prompt_kwargs = prompt_kwargs\n",
    "        self.default_cache = cache\n",
    "        self.default_lock = lock\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(id(self))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self is other\n",
    "\n",
    "    def complete(\n",
    "        self,\n",
    "        *,\n",
    "        api_url: str | auto.typing.Literal[...] = ...,\n",
    "        api_key: str | None | auto.typing.Literal[...] = ...,\n",
    "        session: auto.requests.Session | auto.typing.Literal[...] = ...,\n",
    "        cache: dict[str, auto.typing.Any] | None | auto.typing.Literal[...] = ...,\n",
    "        model: str | None | auto.typing.Literal[...] = ...,\n",
    "        lock: auto.threading.Lock | auto.typing.Literal[...] | None = ...,\n",
    "        **prompt,\n",
    "    ) -> dict[str, auto.typing.Any]:\n",
    "        if api_url is Ellipsis:\n",
    "            api_url = self.default_api_url\n",
    "        if api_key is Ellipsis:\n",
    "            api_key = self.default_api_key\n",
    "        if session is Ellipsis:\n",
    "            session = self.default_session\n",
    "        if cache is Ellipsis:\n",
    "            cache = self.default_cache\n",
    "        if model is Ellipsis:\n",
    "            model = self.default_model\n",
    "        if lock is Ellipsis:\n",
    "            lock = self.default_lock\n",
    "        if lock is None:\n",
    "            lock = auto.contextlib.nullcontext()\n",
    "\n",
    "        prompt = self.default_prompt_kwargs | prompt\n",
    "        if model is not None:\n",
    "            prompt = prompt | dict(\n",
    "                model=model,\n",
    "            )\n",
    "\n",
    "        is_text = 'prompt' in prompt\n",
    "        is_chat = 'messages' in prompt\n",
    "        assert is_text != is_chat, \\\n",
    "            \"Either 'prompt' or 'messages' must be specified.\"\n",
    "\n",
    "        if is_text:\n",
    "            url = f'{api_url}v1/completions'\n",
    "        else:\n",
    "            url = f'{api_url}v1/chat/completions'\n",
    "\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "        }\n",
    "        if api_key is not None:\n",
    "            headers['Authorization'] = f'Bearer {api_key}'\n",
    "\n",
    "        ckey = auto.json.dumps(prompt, sort_keys=True)\n",
    "        with lock:\n",
    "            need = cache is None or ckey not in cache\n",
    "\n",
    "        if need:\n",
    "            with session.request(\n",
    "                'POST',\n",
    "                url,\n",
    "                headers=headers,\n",
    "                json=prompt,\n",
    "            ) as response:\n",
    "                try:\n",
    "                    response.raise_for_status()\n",
    "                except Exception as e:\n",
    "                    raise ValueError(f'API error: {response.text}') from e\n",
    "                output = response.json()\n",
    "\n",
    "            if cache is not None:\n",
    "                with lock:\n",
    "                    cache[ckey] = output\n",
    "\n",
    "            self.was_cached = False\n",
    "\n",
    "        else:\n",
    "            with lock:\n",
    "                output = cache[ckey]\n",
    "\n",
    "            self.was_cached = True\n",
    "\n",
    "        return output\n",
    "\n",
    "    def embed(\n",
    "        self,\n",
    "        input: str | list[str],\n",
    "        *,\n",
    "        api_url: str | auto.typing.Literal[...] = ...,\n",
    "        api_key: str | None | auto.typing.Literal[...] = ...,\n",
    "        session: auto.requests.Session | auto.typing.Literal[...] = ...,\n",
    "        cache: dict[str, auto.typing.Any] | auto.typing.Literal[...] = ...,\n",
    "        model: str | None | Ellipsis = ...,\n",
    "        lock: auto.threading.Lock | auto.typing.Literal[...] | None = ...,\n",
    "        verbose: bool | int = False,\n",
    "    ) -> auto.np.ndarray[float]:\n",
    "        if api_url is Ellipsis:\n",
    "            api_url = self.default_api_url\n",
    "        if api_key is Ellipsis:\n",
    "            api_key = self.default_api_key\n",
    "        if session is Ellipsis:\n",
    "            session = self.default_session\n",
    "        if cache is Ellipsis:\n",
    "            cache = self.default_cache\n",
    "        if model is Ellipsis:\n",
    "            model = self.default_model\n",
    "        if lock is Ellipsis:\n",
    "            lock = self.default_lock\n",
    "        if lock is None:\n",
    "            lock = auto.contextlib.nullcontext()\n",
    "        verbose = int(verbose)\n",
    "\n",
    "        if isinstance(input, str):\n",
    "            input = [input]\n",
    "            one = True\n",
    "        else:\n",
    "            one = False\n",
    "\n",
    "        N = len(input)\n",
    "        K = 100\n",
    "        it = (\n",
    "            (beg, min(N, beg+K))\n",
    "            for beg in range(0, N, K)\n",
    "        )\n",
    "\n",
    "        if verbose >= 1:\n",
    "            pbar = auto.tqdm.auto.tqdm(total=N)\n",
    "\n",
    "        embeds = []\n",
    "        for beg, end in it:\n",
    "            if verbose >= 1:\n",
    "                pbar.update(end-beg)\n",
    "\n",
    "            json = dict(\n",
    "                input=input[beg:end],\n",
    "            )\n",
    "            if model is not None:\n",
    "                json |= dict(\n",
    "                    model=model,\n",
    "                )\n",
    "\n",
    "            ckey = auto.json.dumps(json, sort_keys=True)\n",
    "            with lock:\n",
    "                need = cache is None or ckey not in cache\n",
    "\n",
    "            if need:\n",
    "                with session.request(\n",
    "                    'POST',\n",
    "                    f'{api_url}v1/embeddings',\n",
    "                    headers={\n",
    "                        'Content-Type': 'application/json',\n",
    "                        'Authorization': f'Bearer {api_key}',\n",
    "                    },\n",
    "                    json=json,\n",
    "                ) as response:\n",
    "                    response.raise_for_status()\n",
    "                    output = response.json()\n",
    "\n",
    "                if cache is not None:\n",
    "                    with lock:\n",
    "                        cache[ckey] = output\n",
    "\n",
    "                self.was_cached = False\n",
    "\n",
    "            else:\n",
    "                with lock:\n",
    "                    output = cache[ckey]\n",
    "\n",
    "                self.was_cached = True\n",
    "\n",
    "            for data in output['data']:\n",
    "                embed = data['embedding']\n",
    "                embeds.append(embed)\n",
    "\n",
    "        embeds = auto.np.array(embeds)\n",
    "\n",
    "        if one:\n",
    "            embeds = embeds[0]\n",
    "\n",
    "        return embeds\n",
    "\n",
    "    def tokenize(\n",
    "        self,\n",
    "\n",
    "        input: str,\n",
    "        *,\n",
    "        add_special: bool = False,\n",
    "\n",
    "        api_url: str | auto.typing.Literal[...] = ...,\n",
    "        api_key: str | None | auto.typing.Literal[...] = ...,\n",
    "        session: auto.requests.Session | auto.typing.Literal[...] = ...,\n",
    "        cache: dict[str, auto.typing.Any] | auto.typing.Literal[...] = ...,\n",
    "        model: str | None | auto.typing.Literal[...] = ...,\n",
    "        lock: auto.threading.Lock | auto.typing.Literal[...] | None = ...,\n",
    "    ) -> list[int]:\n",
    "        if api_url is Ellipsis:\n",
    "            api_url = self.default_api_url\n",
    "        if api_key is Ellipsis:\n",
    "            api_key = self.default_api_key\n",
    "        if session is Ellipsis:\n",
    "            session = self.default_session\n",
    "        if cache is Ellipsis:\n",
    "            cache = self.default_cache\n",
    "        if model is Ellipsis:\n",
    "            model = self.default_model\n",
    "        if lock is Ellipsis:\n",
    "            lock = self.default_lock\n",
    "        if lock is None:\n",
    "            lock = auto.contextlib.nullcontext()\n",
    "\n",
    "        url = api_url\n",
    "        url = f'{url}tokenize'\n",
    "\n",
    "        json = dict(\n",
    "            content=input,\n",
    "            add_special=add_special,\n",
    "        )\n",
    "        if model is not None:\n",
    "            json |= dict(\n",
    "                model=model,\n",
    "            )\n",
    "\n",
    "        ckey = auto.json.dumps(json, sort_keys=True)\n",
    "        with lock:\n",
    "            need = cache is None or ckey not in cache\n",
    "\n",
    "        if need:\n",
    "            with session.request(\n",
    "                'POST',\n",
    "                url,\n",
    "                headers={\n",
    "                    'Content-Type': 'application/json',\n",
    "                    'Authorization': f'Bearer {api_key}',\n",
    "                },\n",
    "                json=json,\n",
    "            ) as response:\n",
    "                response.raise_for_status()\n",
    "                json = response.json()\n",
    "\n",
    "            if cache is not None:\n",
    "                with lock:\n",
    "                    cache[ckey] = json\n",
    "\n",
    "            self.was_cached = False\n",
    "\n",
    "        else:\n",
    "            with lock:\n",
    "                json = cache[ckey]\n",
    "\n",
    "            self.was_cached = True\n",
    "\n",
    "        tokens = []\n",
    "        for token in json['tokens']:\n",
    "            tokens.append(token)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def detokenize(\n",
    "        self,\n",
    "\n",
    "        tokints: list[int],\n",
    "        *,\n",
    "        api_url: str | auto.typing.Literal[...] = ...,\n",
    "        api_key: str | None | auto.typing.Literal[...] = ...,\n",
    "        session: auto.requests.Session | auto.typing.Literal[...] = ...,\n",
    "        cache: dict[str, auto.typing.Any] | auto.typing.Literal[...] = ...,\n",
    "        lock: auto.threading.Lock | auto.typing.Literal[...] | None = ...,\n",
    "    ) -> list[str]:\n",
    "        if api_url is Ellipsis:\n",
    "            api_url = self.default_api_url\n",
    "        if api_key is Ellipsis:\n",
    "            api_key = self.default_api_key\n",
    "        if session is Ellipsis:\n",
    "            session = self.default_session\n",
    "        if cache is Ellipsis:\n",
    "            cache = self.default_cache\n",
    "        if lock is Ellipsis:\n",
    "            lock = self.default_lock\n",
    "        if lock is None:\n",
    "            lock = auto.contextlib.nullcontext()\n",
    "\n",
    "        url = api_url\n",
    "        url = f'{url}detokenize'\n",
    "\n",
    "        tokens = []\n",
    "        for tokint in tokints:\n",
    "            json = dict(\n",
    "                tokens=[tokint],\n",
    "            )\n",
    "\n",
    "            ckey = auto.json.dumps(json, sort_keys=True)\n",
    "            with lock:\n",
    "                need = cache is None or ckey not in cache\n",
    "\n",
    "            if need:\n",
    "                with session.request(\n",
    "                    'POST',\n",
    "                    url,\n",
    "                    headers={\n",
    "                        'Content-Type': 'application/json',\n",
    "                        'Authorization': f'Bearer {api_key}',\n",
    "                    },\n",
    "                    json=json,\n",
    "                ) as response:\n",
    "                    response.raise_for_status()\n",
    "                    json = response.json()\n",
    "\n",
    "                if cache is not None:\n",
    "                    with lock:\n",
    "                        cache[ckey] = json\n",
    "\n",
    "                self.was_cached = False\n",
    "\n",
    "            else:\n",
    "                with lock:\n",
    "                    json = cache[ckey]\n",
    "\n",
    "                self.was_cached = True\n",
    "\n",
    "            token = json['content']\n",
    "\n",
    "            tokens.append(token)\n",
    "\n",
    "        return tokens\n",
    "    \n",
    "\n",
    "\n",
    "def LLM(\n",
    "    arg: str | None = None,\n",
    "    /,\n",
    "    *,\n",
    "    api_url: str | auto.typing.Literal[...] = ...,\n",
    "    api_key: str | None | auto.typing.Literal[...] = ...,\n",
    "    api_key_name: str = 'LLAMA_API_KEY',\n",
    "    cache: auto.typing.Literal[...] | None = ...,\n",
    ") -> _LLM:\n",
    "    host, model = arg.split('/', 1)\n",
    "\n",
    "    if api_url is ...:\n",
    "        api_url = {\n",
    "            ('devcloud', 'llama'):\n",
    "                'https://completion.on.devcloud.is.mediocreatbest.xyz/llama/',\n",
    "            ('sahara', 'llama'):\n",
    "                'https://completion.on.sahara.is.mediocreatbest.xyz/llama/',\n",
    "            ('kavir', 'llama'):\n",
    "                'https://completion.on.kavir.is.mediocreatbest.xyz/llama/',\n",
    "            ('nebula', 'llama'):\n",
    "                'https://completion.on.nebula.is.mediocreatbest.xyz/llama/',\n",
    "\n",
    "            ('sahara', 'tinyllama'):\n",
    "                'https://completion.on.sahara.is.mediocreatbest.xyz/tinyllama/',\n",
    "            ('kavir', 'tinyllama'):\n",
    "                'https://completion.on.kavir.is.mediocreatbest.xyz/tinyllama/',\n",
    "            ('nebula', 'tinyllama'):\n",
    "                'https://completion.on.nebula.is.mediocreatbest.xyz/tinyllama/',\n",
    "\n",
    "            ('sahara', 'nomic'):\n",
    "                'https://completion.on.sahara.is.mediocreatbest.xyz/nomic/',\n",
    "            ('kavir', 'nomic'):\n",
    "                'https://completion.on.kavir.is.mediocreatbest.xyz/nomic/',\n",
    "            ('nebula', 'nomic'):\n",
    "                'https://completion.on.nebula.is.mediocreatbest.xyz/nomic/',\n",
    "\n",
    "            ('sahara', 'SFR-Embedding-Mistral'):\n",
    "                'https://completion.on.sahara.is.mediocreatbest.xyz/SFR-Embedding-Mistral/',\n",
    "        }[host, model]\n",
    "\n",
    "    if api_key is ...:\n",
    "        api_key = auto.mediocreatbest.getkey(api_key_name)\n",
    "\n",
    "    if cache is ...:\n",
    "        global __LLM_cache\n",
    "        try: __LLM_cache\n",
    "        except NameError: __LLM_cache = None\n",
    "        if __LLM_cache is None:\n",
    "            __LLM_cache = {}\n",
    "        if model not in __LLM_cache:\n",
    "            __LLM_cache[model] = auto.shelve.open(f'LLM.{model}.shelve', 'c')\n",
    "        cache = __LLM_cache[model]\n",
    "\n",
    "    prompt_kwargs = dict(\n",
    "        max_tokens=300,\n",
    "        temperature=0.0,\n",
    "        # top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        cache_prompt=True,\n",
    "    ) | {\n",
    "        'llama': dict(\n",
    "            stop=[\n",
    "                '<|eot_id|>',\n",
    "            ],\n",
    "        ),\n",
    "        'tinyllama': dict(\n",
    "            stop=[\n",
    "                # '</s>',\n",
    "                '<|endoftext|>',\n",
    "                '<|im_end|>',\n",
    "            ],\n",
    "        ),\n",
    "    }.get(model, {})\n",
    "\n",
    "    llm = _LLM(\n",
    "        model=model,\n",
    "        api_url=api_url,\n",
    "        api_key=api_key,\n",
    "        cache=cache,\n",
    "        prompt_kwargs=prompt_kwargs,\n",
    "    )\n",
    "\n",
    "    return llm\n",
    "\n",
    "def scope(llm, querry):\n",
    "    llm = LLM(llm)\n",
    "\n",
    "    print(llm.embed(f'search_querry: {querry}'))\n",
    "\n",
    "scope(\n",
    "    llm = 'sahara/nomic',\n",
    "    querry = 'major complication',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe style=\"background-color: #fff;\" width=\"1250\" height=\"600\" src=\"http://127.0.0.1:8080\">\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe style=\"background-color: #fff;\" width=\"1250\" height=\"600\" src=\"http://127.0.0.1:8080\">\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "let data;\n",
    "window.addEventListener(\"message\", message_handler);\n",
    "element.text(\"\")\n",
    "\n",
    "function message_handler(event){\n",
    "    event.origin === 'http://127.0.0.1:8080'? data = event.data : ' ';\n",
    "    element.text(data);\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
